{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 What is TensorFlow 2.0, and how is it different from TensorFlow 1.x2\n",
    "\n",
    "TensorFlow 2.0 is an open-source machine learning framework that simplifies deep\n",
    "learning development. It introduces eager execution, enabling immediate evaluation \n",
    "of operations for easier debugging, unlike the graph-based approach in TensorFlow\n",
    " 1.x. TensorFlow 2.0 integrates Keras as the default high-level API, offering a \n",
    "more user-friendly interface for building models. It also reduces boilerplate \n",
    "code, enhances performance with optimizations for distributed training, and \n",
    "improves support for hardware acceleration. Overall, TensorFlow 2.0 provides \n",
    "a cleaner, more Pythonic API, making it easier for developers to create and \n",
    "experiment with machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 .how to you install tenserflow ?\n",
    "pip install tensorflow\n",
    "\n",
    "chek tensorflow download or not \n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. What is the primary function of the tf.function in TensorFlow 2.0?\n",
    "\n",
    "The primary function of tf.function in TensorFlow 2.0 is to convert Python\n",
    "functions into TensorFlow computation graphs for improved performance. \n",
    "It allows TensorFlow to optimize and run operations more efficiently by \n",
    "tracing the function to create a static computation graph, while still \n",
    "enabling the flexibility of Python code. This results in faster execution \n",
    "during training and inference by leveraging TensorFlow's optimizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.What is the purpose of the Model class in TensorFlow 2.0?\n",
    "\n",
    "Model Architecture: It allows users to define the layers and structure of \n",
    "the model (e.g., sequential or functional APIs).\n",
    "Training: It provides methods like fit to train the model on data.\n",
    "Evaluation: It includes methods like evaluate to assess model performance.\n",
    "Inference: It supports predict to make predictions on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. How do you create a neural network using TensorFlow 2.0?\n",
    "\n",
    "Input Layer: The input is a flattened 28x28 image (784 features).\n",
    "Hidden Layer: A dense layer with 128 neurons and ReLU activation function.\n",
    "Output Layer: A dense layer with 10 neurons, each corresponding to a class \n",
    "(0-9) and softmax activation for multi-class classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. What is the importance of Tensor Space in TensorFlow2 ?\n",
    "Representation of Data: Tensors in TensorFlow 2.0 are the core data structure, \n",
    "representing inputs, weights, and outputs in models.\n",
    "\n",
    "Flexibility: Tensors can have any number of dimensions (scalars, vectors, matrices,\n",
    " etc.), allowing TensorFlow to handle a wide range of data formats.\n",
    "Efficient Computation: TensorFlow optimizes tensor operations for performance, \n",
    "making model training and inference faster, especially when working with large \n",
    "datasets.\n",
    "Parallelism: Tensor operations can be executed in parallel on CPUs, GPUs, and \n",
    "TPUs, speeding up computations across tensor spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. How can TensorBoard be integrated with TensorFlow 2.0?\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir='logs', histogram_freq=1)\n",
    "model.fit(train_images, train_labels, epochs=5, callbacks=[tensorboard_callback])\n",
    "tensorboard --logdir=logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. What is the purpose of TensorFlow Playground2\n",
    "\n",
    "Visualize Neural Networks: See how different architectures and hyperparameters\n",
    "affect model training and performance.\n",
    "Experiment with Data: Use datasets like XOR or circles to understand how neural\n",
    "networks learn patterns.\n",
    "Explore Activation Functions: Adjust activation functions, learning rates, and \n",
    "other parameters to see their impact.\n",
    "Understand Deep Learning Concepts: Provide an intuitive way to learn about neural \n",
    "networks without writing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9.What is Netron, and how is it useful for deep learning models2\n",
    "\n",
    "Netron is an open-source tool for visualizing deep learning models in various formats (e.g., TensorFlow, Keras, ONNX, PyTorch). It provides an interactive web-based interface that displays the architecture of models as a graph, making it easier to understand their structure, layers, and connections. Netron is useful for inspecting models, debugging, and explaining complex neural networks. It helps users quickly identify layer configurations, input/output shapes, and other details without diving into code, which is valuable for both developers and researchers working with deep learning models. It supports numerous model formats, improving cross-platform compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10.What is the difference between TensorFlow and PyTorch? \n",
    "Ease of Use: PyTorch has a more Pythonic and intuitive interface.\n",
    "Execution: TensorFlow uses static graphs, while PyTorch uses dynamic graphs.\n",
    "Deployment: TensorFlow has better tools for production deployment (e.g., TensorFlow Serving).\n",
    "Community: TensorFlow has a larger community and more resources.\n",
    "Flexibility: PyTorch offers greater flexibility for research and experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#11. How do you install PyTorch \n",
    " pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#12. What is the basic structure of a PyTorch neural network?\n",
    "Model Definition: Typically done by subclassing torch.nn.Module and defining the layers in the __init__ method.\n",
    "\n",
    "Forward Pass: The forward method defines how input data passes through the layers (the computation graph).\n",
    "\n",
    "Training Loop: Includes the loss function, optimizer, and the loop that iterates over data to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#13.What is the significance of tensors in PyTorch2\n",
    "Multi-dimensional Arrays: Tensors can represent scalars, vectors, matrices, or higher-dimensional data, making them versatile for a wide range of tasks.\n",
    "GPU Acceleration: Tensors can be moved between CPU and GPU, enabling fast computation on GPUs for deep learning tasks.\n",
    "Automatic Differentiation: Tensors support automatic differentiation, enabling efficient backpropagation for training neural networks.\n",
    "Flexible Operations: PyTorch provides a wide range of tensor operations (e.g., addition, matrix multiplication, reshaping) for model building and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#14.What is the difference between torch.Tensor and torch.cuda.Tensor in PyTorch?\n",
    "torch.Tensor:\n",
    "\n",
    "Represents a tensor stored on the CPU by default.\n",
    "Used for general computation on the CPU.\n",
    "Can be moved to the GPU by calling .to(device) or .cuda().\n",
    "torch.cuda.Tensor:\n",
    "\n",
    "Represents a tensor stored directly on the GPU (CUDA-enabled device).\n",
    "Allows for faster computation by utilizing GPU acceleration.\n",
    "Operations on torch.cuda.Tensor are performed on the GPU, improving performance for deep learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#15.What is the purpose of the torch.optim module in PyTorch?\n",
    "Parameter Updates: It adjusts model parameters to reduce the loss function.\n",
    "Support for Common Algorithms: Includes widely used optimizers like Adam, SGD, and more.\n",
    "Learning Rate Scheduling: Allows for the dynamic adjustment of learning rates during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#17.What is the difference between torch.nn.Module and torch.nn.Sequential in PyTorch?\n",
    "\n",
    "torch.nn.Module: Used for creating complex, customizable models.\n",
    "torch.nn.Sequential: A simpler, more concise way to define models with a linear stack of layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#18. How can you monitor training progress in TensorFlow 2.0?\n",
    "TensorBoard is the most comprehensive tool for monitoring training.\n",
    "Use the verbose parameter in fit() for simple output.\n",
    "Custom callbacks and progress bars provide additional flexibility for tracking training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#19. How does the Keras API fit into TensorFlow 2.0?\n",
    "\n",
    "Keras in TensorFlow 2.0 provides a simple, high-level interface for building and training models, while still benefiting from TensorFlow's powerful features like GPU acceleration, distribution, and integration with other components. It's designed for both quick prototyping and production deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#20.What is an example of a deep learning project that can be implemented using TensorFlow 2.0?\n",
    "\n",
    "\n",
    "A deep learning project that can be implemented using TensorFlow 2.0 is image classification using Convolutional Neural Networks (CNNs). For example, you can build a model to classify images from the CIFAR-10 dataset, which contains 10 different classes of objects like airplanes, cars, and animals. The model can be trained, evaluated, and deployed using TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#21. What is the main advantage of using pre-trained models in TensorFlow and PyTorch?\n",
    "The main advantage of using **pre-trained models** in **TensorFlow** and **PyTorch** is **transfer learning**. Pre-trained models are already trained on large datasets (like ImageNet) and can be fine-tuned for specific tasks, saving time and computational resources. They help to:\n",
    "\n",
    "1. **Reduce Training Time**: Skip training from scratch, which is computationally expensive.\n",
    "2. **Improve Performance**: Benefit from the features learned by models on large datasets, especially when working with limited data.\n",
    "3. **Leverage Robust Architectures**: Utilize proven architectures like ResNet, VGG, and BERT, which are well-optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Practical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.How do you install and verify that TensorFlow 2.0 was installed successfully?\n",
    "pip install tensorflow\n",
    "\n",
    "verify\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of the addition is: 8\n"
     ]
    }
   ],
   "source": [
    "#2.How can you define a simple function in TensorFlow 2.0 to perform addition?\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the addition function\n",
    "@tf.function\n",
    "def add_numbers(a, b):\n",
    "    return a + b\n",
    "\n",
    "# Example usage\n",
    "x = tf.constant(5)\n",
    "y = tf.constant(3)\n",
    "result = add_numbers(x, y)\n",
    "\n",
    "print(\"The result of the addition is:\", result.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ram sharma\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#3.How can you create a simple neural network in TensorFlow 2.0 with one hidden layer?\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "\n",
    "model.add(layers.InputLayer(input_shape=(784,)))\n",
    "\n",
    "\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ram sharma\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#4.How can you visualize the training progress using TensorFlow and Matplotlib?\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "\n",
    "model.add(layers.InputLayer(input_shape=(784,)))\n",
    "\n",
    "\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.How do you install PyTorch and verify the PyTorch installation?\n",
    " pip install torch torchvision torchaudio\n",
    "import torch\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7.How do you define a loss function and optimizer in PyTorch?\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8.How do you save and load a TensorFlow model?\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# 1. Define and train a simple model\n",
    "model = models.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(32,)),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Dummy data for training\n",
    "import numpy as np\n",
    "X_train = np.random.random((1000, 32))  # 1000 samples, 32 features\n",
    "y_train = np.random.randint(10, size=(1000,))  # 1000 labels (10 classes)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=2, batch_size=32)\n",
    "\n",
    "# 2. Save the model (full model including architecture, weights, optimizer)\n",
    "model.save(\"my_model\")  # SavedModel format (default)\n",
    "\n",
    "# 3. Load the model back\n",
    "loaded_model = tf.keras.models.load_model(\"my_model\")\n",
    "\n",
    "# 4. Verify that the model works by evaluating on some data\n",
    "loss, accuracy = loaded_model.evaluate(X_train, y_train)\n",
    "print(f\"Loaded model accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
